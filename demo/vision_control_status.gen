-author Eugene Gilmore 

-swift
import bridge

-c
/**
 * @brief Resolutions Supported by Vision
 */
enum Resolutions {
	QQVGA,  ///< 160 x 120
	QVGA,   ///< 320 x 240
	VGA,    ///< 640 x 480
	HD_4VGA,    ///< 1280x960
	SVGA   ///< 800 x 600
};

/**
 * @brief Enum of available camera's that can be used by vision
 */
enum VisionCamera {
	Top, ///< Top Camera on the nao
	Bottom ///< Bottom Camera on the nao
};

/**
 * @brief Enum listing available vision pipelines
 */
enum NamedPipeline {
	Soccer, ///< Soccer Pipeline
	OpenChallenge, ///< 2013 Open Challange Pipeline
	Streaming, ///< Pipeline that just streams images
	Neural_Network, ///< Pipeline to rec objects with a nn
	OpenCVFaces, ///< Pipeline to recognise faces
	HTWK  ///<Pipeline that runs htwk's image algorithms and post soccer object info to mipal whiteboard
};

/**
 * @brief Streaming modes available in vision
 */
enum StreamingType {
	Normal, ///< Images straight from camera
	Classified, ///<Images that has been segmented into recognised colours
	Recognized ///< Image showing only objects that have been recognised NYI
};

/**
 * @brief List of file types that vision can save images as
 */
enum SaveFileType {
	AI2, ///< Raw YUV422 Image
	JPG, ///< Compressed JPEG
	None
};


-properties
enum Resolutions cameraResolution = VGA // Resolution that the camera should caputre images at
bool pipelineRunning = true // Whether the pipeline is running or not
enum VisionCamera selectedCamera = Top // Which camera to use
enum SaveFileType saveImage = None // Whether to save the image used in the next iteration of the pipeline to file
bool saveClassifiedImage = false // Whether to save the classified version of the image used in the next iteration of the pipeline to file
enum NamedPipeline pipeline = Soccer // vision pipeline to be run 
enum StreamingType streamingSource = Normal // The type of streaming to be used
bool imageInput = false // Use /tmp/test.ai2 as pipeline image rather then camera if true
int jpegStreamQuality = 30 // The quality to compress jpeg images at for streaming can be between 0 and 100
int jpegStreamStride = 4 // The stride to use when streaming jpeg images
int frameRate = 0 // The current framerate that the pipeline is running at
bool runPipelineOnce = false // run the pipeline one time only if true
uint64_t frameNumber = 0 // The current frame number reported by guvison
string colourCalibration[10] = "class" //the DLC file to use for segmentation, searched in $HOME/data/ with the .dlc extension

+c++
/**
 * @brief Resolution wrapper class for Resolutions enum
 * Contains a Resolution and provides a number of convenience
 * methods for each resolution. Width Height etc.
 */
class ResolutionType {
private:
	/** The resolution that this object should work with*/
	PROPERTY(Resolutions, resolution)
public:
	/**
	 * @brief Constructor using value from Resolutions enum
	 * @param res The resolution to use
	*/
	ResolutionType(Resolutions res = VGA): _resolution(res) {}

	/** get the width of the current resolution */
	int width() const
	{
		static const int Widths[] = {160, 320, 640, 1280, 800};
		return Widths[_resolution];
	}

	/** get the height of the current resolution */
	int height() const
	{
		static const int Heights[] = {120, 240, 480, 960, 600};
		return Heights[_resolution];
	}
};

-comment
The control status message used by guvision, guvision will post the current state of the pipeline once a frame with the message, various properties can also be set by post a vision_controll message with this type
